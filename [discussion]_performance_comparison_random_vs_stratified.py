# -*- coding: utf-8 -*-
"""[Discussion] Performance comparison Random vs Stratified.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XbkKcmR15yYtp4bqukTZQ651HP4zmNIS
"""

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from matplotlib.ticker import PercentFormatter
from matplotlib.pyplot import figure

import tensorflow as tf

# You'll generate plots of attention in order to see which parts of an image
# your model focuses on during captioning
import matplotlib.pyplot as plt

import collections
import random
import numpy as np
import os
import time
import json
from PIL import Image

#@title Default title text
# Download caption annotation files
annotation_folder = '/annotations/'
if not os.path.exists(os.path.abspath('.') + annotation_folder):
  annotation_zip = tf.keras.utils.get_file('captions.zip',
                                           cache_subdir=os.path.abspath('.'),
                                           origin='http://images.cocodataset.org/annotations/annotations_trainval2014.zip',
                                           extract=True)
  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'
  os.remove(annotation_zip)

# Download image files
image_folder = '/train2014/'
if not os.path.exists(os.path.abspath('.') + image_folder):
  image_zip = tf.keras.utils.get_file('train2014.zip',
                                      cache_subdir=os.path.abspath('.'),
                                      origin='http://images.cocodataset.org/zips/train2014.zip',
                                      extract=True)
  PATH = os.path.dirname(image_zip) + image_folder
  os.remove(image_zip)
else:
  PATH = os.path.abspath('.') + image_folder

with open(annotation_file, 'r') as f:
    annotations = json.load(f)
# Group all captions together having the same image ID.
image_path_to_caption = collections.defaultdict(list)
for val in annotations['annotations']:
  caption = f"<start> {val['caption']} <end>"
  image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (val['image_id'])
  image_path_to_caption[image_path].append(caption)

"""# 1. EVALUATION METRICS

## Result
"""

# Bleus in one-to-all
uploaded = files.upload()
random5000 = pd.read_csv('withoutTM-bleus ota 5000 (rd0).csv')

# Bleus in one-to-one
uploaded = files.upload()
random5000_oto = pd.read_csv('withoutTM-bleus oto 5000 (rd0).csv')

random5000=list(random5000.iloc[:,1])
random5000_oto=list(random5000_oto.iloc[:,1])

# Average
print('one-to-all',np.mean(random5000))
print('one-to-one',np.mean(random5000_oto))

# Distribution between ota oto
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000_oto, bins, alpha=0.5, label='one-to-one',weights=np.ones(len(random5000_oto)) / len(random5000_oto),color = "gray")
plt.hist(random5000, bins, alpha=0.5, label='one-to-all',weights=np.ones(len(random5000)) / len(random5000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# %BLEU<0.1
print('one-to-one:',len([i for i in random5000_oto if i<0.1])*100/len(random5000_oto))
print('one-to-all:',len([i for i in random5000 if i<0.1])*100/len(random5000))

# 0.4<=%BLEU<0.6
print('one-to-one:',len([i for i in random5000_oto if i<0.6 and i>=0.4])*100/len(random5000_oto))
print('one-to-all:',len([i for i in random5000 if i<0.6 and i>=0.4])*100/len(random5000))

# %BLEU>=0.8
print('one-to-one:',len([i for i in random5000_oto if i>=0.8])*100/len(random5000_oto))
print('one-to-all:',len([i for i in random5000 if i>=0.8])*100/len(random5000))

"""# 2. STRATIFICATION IMPACT - ACCURACY

## 2.1. Result
"""

# Bleus Stratified sample 5000
uploaded = files.upload()
strati5000=pd.read_csv('merged-bleus 5000 (rd0).csv')

strati5000=list(strati5000.iloc[:,1])

# Average
print('random',np.mean(random5000))
print('stratified',np.mean(strati5000))

figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000, bins, alpha=0.5, label='random',weights=np.ones(len(random5000)) / len(random5000),color = "gray")
plt.hist(strati5000, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati5000)) / len(strati5000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# % BLEU<0.3
print('random',len([i for i in random5000 if i<0.3])*100/len(random5000))
print('stratified',len([i for i in strati5000 if i<0.3])*100/len(strati5000))

# % 0.6<=BLEU<0.8
print('random',len([i for i in random5000 if i>=0.6 and i<0.8])*100/len(random5000))
print('stratified',len([i for i in strati5000 if i>=0.6 and i<0.8])*100/len(strati5000))

# %BLEU>0.8
print('random',len([i for i in random5000 if i>=0.8])*100/len(random5000))
print('stratified',len([i for i in strati5000 if i>0.8])*100/len(strati5000))

# max BLEU
print('random',max(random5000))
print('stratified',max(strati5000))

"""### Validate the gap by 4 more run times"""

# 2nd trial
uploaded = files.upload()
random5000_2=pd.read_csv('withoutTM-bleus 5000 (rd1).csv')

# 2nd trial
uploaded = files.upload()
strati5000_2=pd.read_csv('merged-bleus 5000 (rd1).csv')

random5000_2=list(random5000_2.iloc[:,1])
strati5000_2=list(strati5000_2.iloc[:,1])
#Averge
print('random',np.mean(random5000_2))
print('stratified',np.mean(strati5000_2))
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000_2, bins, alpha=0.5, label='random',weights=np.ones(len(random5000_2)) / len(random5000_2),color = "gray")
plt.hist(strati5000_2, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati5000_2)) / len(strati5000_2),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# 3rd trial
uploaded = files.upload()
random5000_3=pd.read_csv('withoutTM-bleus 5000 (rd2).csv')

# 3rd trial
uploaded = files.upload()
strati5000_3=pd.read_csv('merged-bleus 5000 (rd2).csv')

random5000_3=list(random5000_3.iloc[:,1])
strati5000_3=list(strati5000_3.iloc[:,1])
#Averge
print('random',np.mean(random5000_3))
print('stratified',np.mean(strati5000_3))
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000_3, bins, alpha=0.5, label='random',weights=np.ones(len(random5000_3)) / len(random5000_3),color = "gray")
plt.hist(strati5000_3, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati5000_3)) / len(strati5000_3),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# 4th trial
uploaded = files.upload()
random5000_4=pd.read_csv('withoutTM-bleus 5000 (rd3).csv')

# 4th trial
uploaded = files.upload()
strati5000_4=pd.read_csv('merged-bleus 5000 (rd3).csv')

random5000_4=list(random5000_4.iloc[:,1])
strati5000_4=list(strati5000_4.iloc[:,1])
#Averge
print('random',np.mean(random5000_4))
print('stratified',np.mean(strati5000_4))
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000_4, bins, alpha=0.5, label='random',weights=np.ones(len(random5000_4)) / len(random5000_4),color = "gray")
plt.hist(strati5000_4, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati5000_4)) / len(strati5000_4),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# 5th trial
uploaded = files.upload()
random5000_5=pd.read_csv('withoutTM-bleus 5000 (rd4).csv')

# 5th trial
uploaded = files.upload()
strati5000_5=pd.read_csv('merged-bleus 5000 (rd4).csv')

random5000_5=list(random5000_5.iloc[:,1])
strati5000_5=list(strati5000_5.iloc[:,1])
#Averge
print('random',np.mean(random5000_5))
print('stratified',np.mean(strati5000_5))
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random5000_5, bins, alpha=0.5, label='random',weights=np.ones(len(random5000_5)) / len(random5000_5),color = "gray")
plt.hist(strati5000_5, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati5000_5)) / len(strati5000_5),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

"""## 2.2. Discussion"""

# Random prediction
uploaded = files.upload()
random_pred=pd.read_csv('withoutTM-pred 5000 (rd0).csv')

# Stratified prediction
uploaded = files.upload()
strati_pred=pd.read_csv('merged-pred 5000 (rd0).csv')

# 5000 captions with topic
uploaded = files.upload()
topic5000=pd.read_csv('5000wtopic.csv')

topic5000.head()

# Merge prediction set in stratified with topic
strati_topic=pd.merge(topic5000,strati_pred,left_on='image_path',right_on='1')

# Merge prediction set in random with topic
random_topic=pd.merge(topic5000,random_pred,left_on='image_path',right_on='1')

# Compute the mean score for each topic
random_score=[]
strati_score=[]
for i in range(30):
  strati_score.append(np.mean(strati_pred.loc[strati_pred['1'].isin(strati_topic.loc[strati_topic['Dominant_Topic']==i,'image_path'])==True,['0']]))
  random_score.append(np.mean(random_pred.loc[random_pred['1'].isin(random_topic.loc[random_topic['Dominant_Topic']==i,'image_path'])==True,['0']]))

#plot the mean score for each topic
figure(figsize=(10,3))
x = range(30)

plt.plot(x, strati_score,color = "deepskyblue", label='stratified')
plt.plot(x, random_score,color = "gray", label='random')
plt.xlabel("Topic")
plt.ylabel("BLEU")
plt.xticks([0,5,10,15,20,25,30])
plt.show()

# create list of topic in prediction set
random_test=list(random_topic['Dominant_Topic'])
strati_test=list(strati_topic['Dominant_Topic'])

# plot the distribution topic between random & stratified (stratified represent whole sample)

figure(figsize=(10,3))
bins = 30
plt.hist(random_test, bins, alpha=0.5, label='random - test',weights=np.ones(len(random_test)) / len(random_test),color = "gray")
plt.hist(strati_test, bins, alpha=0.5, label='stratified - test',weights=np.ones(len(strati_test)) / len(strati_test),color = "deepskyblue")
plt.legend(loc='upper left')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('Topic')
plt.show()

# Caption in topic that have similar average score
for i in random_topic[random_topic['Dominant_Topic']==4]['image_path'].values:
  if i in strati_topic[strati_topic['Dominant_Topic']==4]['image_path'].values:
    print(i)
    print('random', random_topic[random_topic['image_path']==i]['3'].values,random_topic[random_topic['image_path']==i]['0_y'].values)
    print('stratified', strati_topic[strati_topic['image_path']==i]['3'].values,strati_topic[strati_topic['image_path']==i]['0_y'].values)

Image.open('/content/train2014/COCO_train2014_000000250278.jpg')

Image.open('/content/train2014/COCO_train2014_000000434943.jpg')



"""# 3. STRATIFICATION IMPACT - SCALABILITY

## 3.1. Result
"""

#1000
uploaded = files.upload()
random_bleus1000=pd.read_csv('withoutTM-bleus 1000.csv')
uploaded = files.upload()
strati_bleus1000=pd.read_csv('merged-bleus 1000.csv')

random_bleus1000=list(random_bleus1000.iloc[:,1])
strati_bleus1000=list(strati_bleus1000.iloc[:,1])
#Averge
mean_random1000=np.mean(random_bleus1000)
mean_strati1000=np.mean(strati_bleus1000)
print('random',mean_random1000)
print('stratified',mean_strati1000)
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random_bleus1000, bins, alpha=0.5, label='random',weights=np.ones(len(random_bleus1000)) / len(random_bleus1000),color = "gray")
plt.hist(strati_bleus1000, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati_bleus1000)) / len(strati_bleus1000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

#5000
uploaded = files.upload()
random_bleus5000=pd.read_csv('withoutTM-bleus ota 5000 (rd0).csv')
uploaded = files.upload()
strati_bleus5000=pd.read_csv('merged-bleus 5000 (rd0).csv')

random_bleus5000=list(random_bleus5000.iloc[:,1])
strati_bleus5000=list(strati_bleus5000.iloc[:,1])
#Averge
mean_random5000=np.mean(random_bleus5000)
mean_strati5000=np.mean(strati_bleus5000)
print('random',mean_random5000)
print('stratified',mean_strati5000)
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random_bleus5000, bins, alpha=0.5, label='random',weights=np.ones(len(random_bleus5000)) / len(random_bleus5000),color = "gray")
plt.hist(strati_bleus5000, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati_bleus5000)) / len(strati_bleus5000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

#9000
uploaded = files.upload()
random_bleus9000=pd.read_csv('withoutTM-bleus 9000.csv')
uploaded = files.upload()
strati_bleus9000=pd.read_csv('merged-bleus 9000.csv')

random_bleus9000=list(random_bleus9000.iloc[:,1])
strati_bleus9000=list(strati_bleus9000.iloc[:,1])
#Averge
mean_random9000=np.mean(random_bleus9000)
mean_strati9000=np.mean(strati_bleus9000)
print('random',mean_random9000)
print('stratified',mean_strati9000)
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random_bleus9000, bins, alpha=0.5, label='random',weights=np.ones(len(random_bleus9000)) / len(random_bleus9000),color = "gray")
plt.hist(strati_bleus9000, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati_bleus9000)) / len(strati_bleus9000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

#13000
uploaded = files.upload()
random_bleus13000=pd.read_csv('withoutTM-bleus 13000.csv')
uploaded = files.upload()
strati_bleus13000=pd.read_csv('merged-bleus 13000.csv')

random_bleus13000=list(random_bleus13000.iloc[:,1])
strati_bleus13000=list(strati_bleus13000.iloc[:,1])
#Averge
mean_random13000=np.mean(random_bleus13000)
mean_strati13000=np.mean(strati_bleus13000)
print('random',mean_random13000)
print('stratified',mean_strati13000)
#Distribution
figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(random_bleus13000, bins, alpha=0.5, label='random',weights=np.ones(len(random_bleus13000)) / len(random_bleus13000),color = "gray")
plt.hist(strati_bleus13000, bins, alpha=0.5, label='stratified',weights=np.ones(len(strati_bleus13000)) / len(strati_bleus13000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

figure(figsize=(7,3))
sample=range(1000,14000,4000)
random_bleus=[mean_random1000,mean_random5000,mean_random9000, mean_random13000]
strati_bleus=[mean_strati1000,mean_strati5000,mean_strati9000, mean_strati13000]
plt.plot(sample, strati_bleus,color = "deepskyblue", label='stratified')
plt.plot(sample, random_bleus,color = "gray", label='random')

plt.legend(loc='lower right')
plt.xlabel("Sample size")
plt.ylabel("BLEU")
plt.xticks(sample)
plt.show()

"""## 3.2. Discussion

1000 samples
"""

#random prediction
uploaded = files.upload()
random_1000=pd.read_csv('withoutTM-pred 1000.csv')

#strati prediction
uploaded = files.upload()
strati_1000=pd.read_csv('merged-pred 1000.csv')

#topic
uploaded = files.upload()
topic1000=pd.read_csv('1000wtopic.csv')

# merge random prediction with topic
random_topic1000=pd.merge(topic1000,random_1000,left_on='image_path',right_on='1')

# merge stratified prediction with topic
strati_topic1000=pd.merge(topic1000,strati_1000,left_on='image_path',right_on='1')

# Plot topic distribution between random & stratified
from matplotlib.ticker import PercentFormatter
random_test1000=random_topic1000['Dominant_Topic']
strati_test1000=strati_topic1000['Dominant_Topic']
figure(figsize=(10,7))
bins = 30
plt.hist(random_test1000, bins, alpha=0.5, label='random - 1000',weights=np.ones(len(random_test1000)) / len(random_test1000),color = "gray")
plt.hist(strati_test1000, bins, alpha=0.5, label='stratified - 1000',weights=np.ones(len(strati_test1000)) / len(strati_test1000),color = "skyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('Topic')
plt.show()



"""13000 samples"""

# random prediction
uploaded = files.upload()
random_13000=pd.read_csv('withoutTM-pred 13000.csv')

# stratified prediction
uploaded = files.upload()
strati_13000=pd.read_csv('merged-pred 13000.csv')

# topic
uploaded = files.upload()
topic13000=pd.read_csv('13000wtopic.csv')

# merge random prediction with topic
random_topic13000=pd.merge(topic13000,random_13000,left_on='image_path',right_on='1')

# merge stratified prediction with topic
strati_topic13000=pd.merge(topic13000,strati_13000,left_on='image_path',right_on='1')

#plot topic distribution between random and stratified
random_test13000=random_topic13000['Dominant_Topic']
strati_test13000=strati_topic13000['Dominant_Topic']
figure(figsize=(10,7))
bins = 50
plt.hist(random_test13000, bins, alpha=0.5, label='random - 13000',weights=np.ones(len(random_test13000)) / len(random_test13000),color = "gray")
plt.hist(strati_test13000, bins, alpha=0.5, label='stratified - 13000',weights=np.ones(len(strati_test13000)) / len(strati_test13000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('Topic')
plt.show()



"""5000 samples"""

# random prediction
uploaded = files.upload()
random_5000=pd.read_csv('withoutTM-pred 5000 (rd0).csv')

#stratified prediction
uploaded = files.upload()
strati_5000=pd.read_csv('merged-pred 5000 (rd0).csv')

#topic
uploaded = files.upload()
topic5000=pd.read_csv('5000wtopic.csv')

# merge random prediction with topic
random_topic5000=pd.merge(topic5000,random_5000,left_on='image_path',right_on='1')

# merge stratified prediction with topic
strati_topic5000=pd.merge(topic5000,strati_5000,left_on='image_path',right_on='1')

# plot topic distribution between random & stratified
from matplotlib.ticker import PercentFormatter
random_test5000=random_topic5000['Dominant_Topic']
strati_test5000=strati_topic5000['Dominant_Topic']
figure(figsize=(10,7))
bins = 30
plt.hist(random_test5000, bins, alpha=0.5, label='random - 5000',weights=np.ones(len(random_test5000)) / len(random_test5000),color = "gray")
plt.hist(strati_test5000, bins, alpha=0.5, label='stratified - 5000',weights=np.ones(len(strati_test5000)) / len(strati_test5000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('Topic')
plt.show()



"""9000 samples"""

# random prediction
uploaded = files.upload()
random_9000=pd.read_csv('withoutTM-pred 9000.csv')

# stratified prediction
uploaded = files.upload()
strati_9000=pd.read_csv('merged-pred 9000.csv')

# topic
uploaded = files.upload()
topic9000=pd.read_csv('9000wtopic.csv')

# merge random prediction with topic
random_topic9000=pd.merge(topic9000,random_9000,left_on='image_path',right_on='1')

# merge stratified prediction with topic
strati_topic9000=pd.merge(topic9000,strati_9000,left_on='image_path',right_on='1')

#plot topic distribution between random and stratified
from matplotlib.ticker import PercentFormatter
random_test9000=random_topic9000['Dominant_Topic']
strati_test9000=strati_topic9000['Dominant_Topic']
figure(figsize=(10,7))
bins = 30
plt.hist(random_test9000, bins, alpha=0.5, label='random - 9000',weights=np.ones(len(random_test9000)) / len(random_test9000),color = "gray")
plt.hist(strati_test9000, bins, alpha=0.5, label='stratified - 9000',weights=np.ones(len(strati_test9000)) / len(strati_test9000),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('Topic')
plt.show()

#Compute average %gap of topic sample between random & stratified 
gap13000=0
for i in range(50):
  # compute % of topic
  rand=len([j for j in random_test13000 if j ==i])/len(random_test13000)*100
  stra=len([j for j in strati_test13000 if j ==i])/len(random_test13000)*100
  # compute different in %
  gap13000+=(abs(rand-stra))
print(gap13000/50)

#Compute average %gap of topic sample between random & stratified 
gap9000=0
for i in range(30):
  # compute % of topic
  rand=len([j for j in random_test9000 if j ==i])/len(random_test9000)*100
  stra=len([j for j in strati_test9000 if j ==i])/len(random_test9000)*100
  # compute different in %
  gap9000+=(abs(rand-stra))
print(gap9000/30)

#Compute average %gap of topic sample between random & stratified 
gap5000=0
for i in range(30):
  # compute % of topic
  rand=len([j for j in random_test5000 if j ==i])/len(random_test5000)*100
  stra=len([j for j in strati_test5000 if j ==i])/len(random_test5000)*100
  # compute different in %
  gap5000+=(abs(rand-stra))
print(gap5000/30)

#Compute average %gap of topic sample between random & stratified 
gap1000=0
for i in range(30):
  # compute % of topic
  rand=len([j for j in random_test1000 if j ==i])/len(random_test1000)*100
  stra=len([j for j in strati_test1000 if j ==i])/len(random_test1000)*100
  # compute different in %
  gap1000+=(abs(rand-stra))
  
print(gap1000/30)

# plotiing gap in BLEU vs gap in topic distribution

sample=range(1000,14000,4000)
gap_topic=[gap1000/30,gap5000/30,gap9000/30, gap13000/50]
gap_improve=np.array(withtopic_bleus)-np.array(notopic_bleus)
fig, ax1 = plt.subplots(1,1,figsize=(10,4))

ax1.set_xlabel('Sample size')
ax1.set_ylabel('gap per topic', color='gray')
ax1.plot(sample, gap_topic, color='gray')
ax1.tick_params(axis='y', labelcolor='gray')

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

ax2.set_ylabel('BLEU gap', color='deepskyblue')  # we already handled the x-label with ax1
ax2.plot(sample, gap_improve, color='deepskyblue')
ax2.tick_params(axis='y', labelcolor='deepskyblue')
plt.xticks(sample)
fig.tight_layout()  # otherwise the right y-label is slightly clipped
plt.show()





"""# 4. IMAGE ENCODERS

## 4.2 Discussion 
<No Result Figures here as: 
- epoch take from other notebooks.
- accuracy draw in word>
"""

# bleus inception 30 epoch (highest score)
uploaded = files.upload()
strati_inception_bleus=pd.read_csv('merged-bleus 5000 30epoch.csv')
# bleus effnet 20 epoch (highest score)
uploaded = files.upload()
strati_efficient_bleus=pd.read_csv('merged - EffNet bleus 20epoch.csv')

# prediction inception 30 epoch (highest score)
uploaded = files.upload()
strati_inception_pred=pd.read_csv('merged-pred 5000 30epoch.csv')
# prediction effnet 30 epoch (highest score)
uploaded = files.upload()
strati_efficient_pred=pd.read_csv('merged - EffNet pred 20epoch.csv')

#plot bleus distribution
from matplotlib.ticker import PercentFormatter
from matplotlib.pyplot import figure
strati_inception_bleus1=list(strati_inception_bleus.iloc[:,1])
strati_efficient_bleus1=list(strati_efficient_bleus.iloc[:,1])

figure(figsize=(7,4))
bins = np.linspace(0, 1, 10)
plt.hist(strati_efficient_bleus1, bins, alpha=0.5, label='EfficientNetB7',weights=np.ones(len(strati_efficient_bleus1)) / len(strati_efficient_bleus1),color = "gray")
plt.hist(strati_inception_bleus1, bins, alpha=0.5, label='InceptionV3',weights=np.ones(len(strati_inception_bleus1)) / len(strati_inception_bleus1),color = "deepskyblue")
plt.legend(loc='upper right')
plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
plt.ylabel('% of captions')
plt.xlabel('BLEU-1')
plt.show()

# max score
print('Efficient:',max(strati_efficient_bleus1))
print('Inception:',max(strati_inception_bleus1))

# merge 2 table of prediction
incept_effi=pd.merge(strati_inception_pred,strati_efficient_pred,on='1')

incept_effi

# bad prediction from EffNet
effi_bad=incept_effi[incept_effi['0_y']<=0.3]

# Check bad prediction frm EffNet see significant higher in length
image2=effi_bad['1'].values
for i in image2[:10]:
  print(i)
  print('original',incept_effi[incept_effi['1']==i]['2_x'].values) 
  print('inception',incept_effi[incept_effi['1']==i]['0_x'].values,incept_effi[incept_effi['1']==i]['3_x'].values) 
  print('efficient',incept_effi[incept_effi['1']==i]['0_y'].values,incept_effi[incept_effi['1']==i]['3_y'].values)

Image.open('/content/train2014/COCO_train2014_000000335236.jpg')

# Check average length of sentence in original set, and prediction or Inception & EffNet
efficient_word=0
inception_word=0
original_word=0
for i in range(len(incept_effi)):
  # split token
  incept=incept_effi.iloc[i,4][2:-2].split(',')
  effi=incept_effi.iloc[i,8][2:-2].split(',')
  original=incept_effi.iloc[i,3][2:-2].split(',')
  #count total words
  inception_word+=len(incept)
  efficient_word+=len(effi)
  original_word+=len(original)

print('Avg length inception: ', inception_word/len(incept_effi))
print('Avg length efficient: ', efficient_word/len(incept_effi))
print('Avg length original: ', original_word/(len(incept_effi)*5))

# Check average length of bad caption in Inception & Efficient
efficient_bad_word=0
inception_bad_word=0

for i in range(len(effi_bad)):
  # split token
  effi=effi_bad.iloc[i,8][2:-2].split(',')
  #count total words
  efficient_bad_word+=len(effi)

#create data of bad caption from inception
incept_bad=incept_effi[incept_effi['0_x']<=0.3]

for i in range(len(incept_bad)):
  # split token
  incept=incept_bad.iloc[i,8][2:-2].split(',')
  #count total words
  inception_bad_word+=len(incept)

print('Avg length bad efficient',efficient_bad_word/len(effi_bad))
print('Avg length bad inception',inception_bad_word/len(incept_bad))

for i in incept_effi[incept_effi['0_x']==0.5]['1'].values:
  print(i)
  print('inception',incept_effi[incept_effi['1']==i]['0_x'].values,incept_effi[incept_effi['1']==i]['3_x'].values)

Image.open('/content/train2014/COCO_train2014_000000346437.jpg')

incept_effi[incept_effi['1']=='/content/train2014/COCO_train2014_000000346437.jpg']['2_x'].values

Image.open('/content/train2014/COCO_train2014_000000044488.jpg')

incept_effi[incept_effi['1']=='/content/train2014/COCO_train2014_000000044488.jpg']['2_x'].values

incept_effi[incept_effi['1']=='/content/train2014/COCO_train2014_000000044488.jpg']['0_x'].values

incept_effi[incept_effi['1']=='/content/train2014/COCO_train2014_000000044488.jpg']['3_x'].values

